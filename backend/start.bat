@echo off
title Local AI Backend Server
echo ðŸš€ Starting Local AI Backend Server...
echo.

:: Check if Ollama is running
echo ðŸ” Checking Ollama service...
curl -s http://localhost:11434/api/tags >nul 2>&1
if %ERRORLEVEL% == 0 (
    echo âœ… Ollama is running on http://localhost:11434
) else (
    echo âŒ Ollama is not running
    echo ðŸ’¡ Please start Ollama first: ollama serve
    echo.
    pause
    exit /b 1
)

:: Check if server executable exists
if not exist "bin\server.exe" (
    echo âŒ Server executable not found
    echo ðŸ”¨ Building server first...
    call build.bat
    if %ERRORLEVEL% NEQ 0 (
        echo âŒ Build failed, cannot start server
        pause
        exit /b 1
    )
)

echo.
echo ðŸŒ Starting backend server...
echo    API: http://localhost:8082/api/v1
echo    Health: http://localhost:8082/health
echo    Models: http://localhost:8082/api/v1/models
echo.
echo ðŸ“‹ Available models in Ollama:
ollama list 2>nul | findstr /C:"nemotron-nano" /C:"neural-chat" /C:"openchat" /C:"llama2-chat" /C:"phi2"
echo.
echo ðŸ’¡ Press Ctrl+C to stop the server
echo.

:: Start the server
bin\server.exe

echo.
echo ðŸ›‘ Server stopped.
pause
